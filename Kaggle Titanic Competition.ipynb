{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fcae83",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6cf40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Pandas for Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "##SKLearn for Machine Model Tools\n",
    "\n",
    "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
    "from sklearn.model_selection import GridSearchCV # cross validation\n",
    "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
    "\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d60ac7",
   "metadata": {},
   "source": [
    "### Create Function to inspect DataFrame at high Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1af9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_overview(df):\n",
    "    print(\"DataFrame info:\")\n",
    "    print(\"--------------------\")\n",
    "    print(df.info())\n",
    "    print(\"\\nDescribe DataFrame:\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nCount(Distinct):\")\n",
    "    print(\"-------------------------\")\n",
    "    print(df.nunique())\n",
    "    print(f\"\\nNumber of observations: {df.shape[0]}\")\n",
    "    print(\"\\nData Types:\")\n",
    "    print(\"-----------\")\n",
    "    print(df.dtypes)\n",
    "    ##titanic_df_train.isna().sum()\n",
    "    print(\"\\nIsNASum:\")\n",
    "    print(\"-----------\")\n",
    "    print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0177b92",
   "metadata": {},
   "source": [
    "# ML Step # 1: Problem Identification\n",
    "\n",
    "### Problem Definition: Predicting Life or Death in the RMS Titanic\n",
    "The Titanic was a luxury British steamship that sank on its maiden voyage after hitting an iceberg on April 1912. The ship had lifeboats, but not enough for everyone.\n",
    "Among the 2240 total passengers 1517 perished. And although there was some element of luck in getting on a lifeboat, some groups were more likely to get on a lifeboat than others.\n",
    "In this notebook we will try to create a model that determines whether or not someone was likely to survive using passenger data (ie name, age, gender, socio-economic class, etc) collected prior to embarking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ef649",
   "metadata": {},
   "source": [
    "# ML Step # 2: Data Collection\n",
    "\n",
    "### Load the Test and Training file Kaggle provides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ed5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df_train = pd.read_csv('train.csv')\n",
    "titanic_df_test = pd.read_csv('test.csv')\n",
    "\n",
    "##Combine the files to make Feature Engineering Easier\n",
    "\n",
    "concatenated_df = pd.concat([titanic_df_train, titanic_df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce454af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame info:\n",
      "--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n",
      "None\n",
      "\n",
      "Describe DataFrame:\n",
      "---------------------------------------------\n",
      "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
      "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
      "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
      "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
      "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
      "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
      "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
      "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
      "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
      "\n",
      "             Parch         Fare  \n",
      "count  1309.000000  1308.000000  \n",
      "mean      0.385027    33.295479  \n",
      "std       0.865560    51.758668  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     7.895800  \n",
      "50%       0.000000    14.454200  \n",
      "75%       0.000000    31.275000  \n",
      "max       9.000000   512.329200  \n",
      "\n",
      "Count(Distinct):\n",
      "-------------------------\n",
      "PassengerId    1309\n",
      "Survived          2\n",
      "Pclass            3\n",
      "Name           1307\n",
      "Sex               2\n",
      "Age              98\n",
      "SibSp             7\n",
      "Parch             8\n",
      "Ticket          929\n",
      "Fare            281\n",
      "Cabin           186\n",
      "Embarked          3\n",
      "dtype: int64\n",
      "\n",
      "Number of observations: 1309\n",
      "\n",
      "Data Types:\n",
      "-----------\n",
      "PassengerId      int64\n",
      "Survived       float64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "IsNASum:\n",
      "-----------\n",
      "PassengerId       0\n",
      "Survived        418\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataframe_overview(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627d4ed",
   "metadata": {},
   "source": [
    "\n",
    "# ML Step #3: Data Preparation, Feature Engineering\n",
    "###### Variable by Variable\n",
    "\n",
    "\n",
    "#### Ensuring Data Is Tidy\n",
    "#### Handling Missing Data\n",
    "#### Label Encoding\n",
    "#### Transforming Continuous variables\n",
    "#### Recoding Categorical Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af4a85",
   "metadata": {},
   "source": [
    "#### Variable #1:  Name\n",
    "\n",
    "From this variable we will extract the title.  For titles that are less common we label as \"TitleOfRespect\" as they follow this trend of having a title of status, due to occupation or birth.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638c7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Title from Name from it's postion in relation to delimitting comma, and period\n",
    "\n",
    "concatenated_df['Title'] = concatenated_df['Name'].apply(lambda x: x.split(', ')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_counts = concatenated_df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8930c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grouping the Infrequent Titles- All are titles of higher class, or achieved status\n",
    "\n",
    "concatenated_df['Title'] = concatenated_df['Title'].apply(lambda x: x if title_counts[x] > 10 else 'TitleOfRespect')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd4cfc",
   "metadata": {},
   "source": [
    "#### Variable #2:  Gender\n",
    "\n",
    "Made the field numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd876ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['Sex'] = concatenated_df.Sex.apply(lambda x: 0 if x == \"female\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eead3c",
   "metadata": {},
   "source": [
    "#### Variable #3:  Pclass\n",
    "\n",
    "No transformation necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcc172b",
   "metadata": {},
   "source": [
    "#### Variable #4:  Age\n",
    "\n",
    "Imputed missing Age values by calculating median Age by Class.\n",
    "Created Categorical Variable by what Age Group they were in.(Children Teens, Young Adults etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0c0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Impute missing Age fields by assigning median Age for their Passenger Class\n",
    "\n",
    "AgeByPclass = concatenated_df.groupby(['Pclass']).median('Age')['Age'].to_dict()\n",
    "\n",
    "concatenated_df['Age'] = concatenated_df.apply(lambda x: x.Age if not pd.isna(x.Age) else AgeByPclass[x.Pclass],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f267a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "##concatenated_df[concatenated_df['Fare'] < 100]\n",
    "\n",
    "\n",
    "sns.histplot(concatenated_df['Age'][concatenated_df['Age'] < 100], bins=100, kde=True)  # KDE line adds a density plot\n",
    "plt.xlabel('Age')  # Replace with your column name\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Age')  # Replace with your column title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ddcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketAges(value):\n",
    "    if value < 13:\n",
    "        return 'C'\n",
    "    elif 13 <= value < 20:\n",
    "        return 'T'\n",
    "    elif  20 <= value < 35:\n",
    "        return 'YA'\n",
    "    elif  35 <= value < 50:\n",
    "        return 'A'\n",
    "    else:\n",
    "        return 'E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2902e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['AgeCategory'] = concatenated_df['Age'].apply(bucketAges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45eb9dd",
   "metadata": {},
   "source": [
    "#### Variable #5 and #6: Parch and Sibsp\n",
    "\n",
    "These numbers represent the number of parents or children, and the number of siblings. By adding them the result is the number of family members they had on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "029d480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['FamilyOnBoard'] = concatenated_df['Parch'] + concatenated_df['SibSp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287196d",
   "metadata": {},
   "source": [
    "#### Variable #7 Ticket\n",
    "\n",
    "This variable was transformed to create several new variables.\n",
    "\n",
    "TicketCount was created by using the number of passengers who have the same ticket code.\n",
    "IsTicketAlone was used to denote whether or not the ticket was only attributed to a single passenger.\n",
    "Higher Level Ticket Code Groups were created based on the Prefix of the ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ab7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_count = concatenated_df['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c555ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['isTicketAlone'] = concatenated_df['Ticket'].apply(lambda x: 0 if ticket_count[str(x)]<=1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073cc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['CountOfTickets'] = concatenated_df['Ticket'].apply(lambda x: ticket_count[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dfe54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['TicketCode'] = concatenated_df['Ticket'].apply(lambda x: str(x[:1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31d73e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_asis = ['1', '2', '3', 'S', 'P', 'C', 'A']\n",
    "T_ls = ['4','5','6','7','8','L','W' ]\n",
    "# 1, 2, 3, S, P, C, A - Leave as is\n",
    "# 4,5,6,7,8,L,W - Low Survival\n",
    "# Rest - High Survival\n",
    "def bin_ticket(tckt):\n",
    "    if tckt in T_asis:\n",
    "        return tckt\n",
    "    elif tckt in T_ls:\n",
    "        return 'LS'\n",
    "    else:\n",
    "        return 'HS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc78e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['TicketCodeShort'] = concatenated_df['TicketCode'].apply(lambda x: bin_ticket(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316095d",
   "metadata": {},
   "source": [
    "#### Variable #8 Fare\n",
    "\n",
    "Fare prices fall into certain price levels, which also coincide with percentiles, we just use that trend to bucket the Fares into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993745ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "FareByPclass = concatenated_df.groupby(['Pclass']).median('Fare')['Fare'].to_dict()\n",
    "FareByPclass\n",
    "\n",
    "concatenated_df['Fare'] = concatenated_df.apply(lambda x: x.Fare if not pd.isna(x.Fare) else FareByPclass[x.Pclass],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ec0112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 (25th percentile): 7.8958\n",
      "Median (50th percentile): 14.4542\n",
      "Q3 (75th percentile): 31.275\n"
     ]
    }
   ],
   "source": [
    "Q1 = concatenated_df['Fare'].quantile(0.25)\n",
    "Q2 = concatenated_df['Fare'].quantile(0.5)  # This is also the median\n",
    "Q3 = concatenated_df['Fare'].quantile(0.75)\n",
    "\n",
    "print(f\"Q1 (25th percentile): {Q1}\")\n",
    "print(f\"Median (50th percentile): {Q2}\")\n",
    "print(f\"Q3 (75th percentile): {Q3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2958c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeFareCategory(value):\n",
    "    if value < 7.9:\n",
    "        return 'V'\n",
    "    elif 7.9 <= value < 14.5:\n",
    "        return 'C'\n",
    "    elif value < 31.275:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22442c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['FareCategory'] = concatenated_df['Fare'].apply(MakeFareCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244fc51a",
   "metadata": {},
   "source": [
    "#### Variable #9 Cabin\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "583d467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['has_cabin'] = concatenated_df['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "concatenated_df['Cabin'].fillna('Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40a6ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['CabinCode'] = concatenated_df['Cabin'].apply(lambda x:str(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ac73ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_cabin_letter(pclass,cabin_code):\n",
    "    if pclass == 1 and cabin_code == 'U':\n",
    "        return 'C'\n",
    "    elif pclass == 2 and cabin_code == 'U':\n",
    "        return 'D'\n",
    "    elif pclass == 3 and cabin_code == 'U':\n",
    "        return 'G'\n",
    "    elif cabin_code == 'T':\n",
    "        return 'C'\n",
    "    else:\n",
    "        return cabin_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6d1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['CabinCode'] = concatenated_df.apply(lambda x: change_cabin_letter(x.Pclass,x.CabinCode),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3993cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "if 'has_cabin' in concatenated_df.columns:\n",
    "    concatenated_df = concatenated_df.drop(columns=['has_cabin'])\n",
    "    \n",
    "concatenated_df = concatenated_df.drop(columns = ['Cabin','Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a399517",
   "metadata": {},
   "source": [
    "#### Variable #10 Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c21e502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_mode = concatenated_df['Embarked'].mode()[0]\n",
    "embarked_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7189364",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['Embarked'].fillna(embarked_mode,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc35cfd",
   "metadata": {},
   "source": [
    "### Last Data Preparation Steps\n",
    "\n",
    "Dropping unused variables\n",
    "Creating Dummy variables\n",
    "Scaling variables\n",
    "\n",
    "Splitting up our Label, or variable that we are predicting, and the rest of our feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab295942",
   "metadata": {},
   "source": [
    "### Split Tidy data into Dependent, Indepent Variables, Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82d1089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df = concatenated_df.drop(['PassengerId',\n",
    "                              'SibSp', 'Parch', 'Ticket',  'TicketCode'], axis=1).copy() # alternatively: X = df_no_missing.iloc[:,:-1]\n",
    "\n",
    "\n",
    "ds_df = pd.get_dummies(ds_df, columns=['Embarked', 'Title', 'TicketCodeShort', 'CabinCode', 'AgeCategory', 'FareCategory'])\n",
    "\n",
    "X_train = ds_df[~ds_df['Survived'].isna()]\n",
    "X_test = ds_df[ds_df['Survived'].isna()]\n",
    "y_train = ds_df['Survived'][~ds_df['Survived'].isna()]\n",
    "X_train= X_train.drop(['Survived'], axis =1).copy()\n",
    "X_test= X_test.drop(['Survived'], axis =1).copy()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e207a5",
   "metadata": {},
   "source": [
    "# ML Step #4:  Model Selection\n",
    "\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdd89332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "{'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200, 'random_state': 0, 'reg_lambda': 10.0}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb # XGBoost stuff\n",
    "\n",
    "## NOTE: This code takes a few minutes to run, so I've commented it out.\n",
    "## Since I set seed=42, we'll get the same results anyway, and those are\n",
    "## coded into the next section...\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'n_estimators': range(50, 250, 50),\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'gamma': [0, 0.25, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 1.0, 10.0, 100.0],\n",
    "    'random_state': [0]\n",
    "}\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(objective='binary:logistic', eval_metric=\"logloss\", seed=23, use_label_encoder=False),\n",
    "    param_grid=param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs = 10,\n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "optimal_params.fit(X_train, y_train)\n",
    "print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74313043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9023569023569024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get the best model\n",
    "best_model = optimal_params.best_estimator_\n",
    "\n",
    "# Predict on the training data\n",
    "train_predictions = best_model.predict(X_train)\n",
    "\n",
    "# Calculate training accuracy\n",
    "training_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "# Print training accuracy\n",
    "print(\"Training Accuracy:\", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a407bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read sample submit file\n",
    "sample_submit_file = pd.read_csv('gender_submission.csv')\n",
    "\n",
    "# Predict on the training data\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "optim_xg_submitfile = sample_submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "998b5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##optim_xg_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions)], axis=1)\n",
    "##optim_xg_submitfile.rename(columns={optim_xg_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "##optim_xg_submitfile.to_csv('result_optimizedxgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1a206",
   "metadata": {},
   "source": [
    "### ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "722d058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for AdaBoost Classifier:\n",
      "{'learning_rate': 1.0, 'n_estimators': 10}\n",
      "Best score:  0.8305065595380077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "clf_adaboost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(clf_adaboost, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best AdaBoost model from the grid search\n",
    "clf_adaboost_optimized = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Best Hyperparameters for AdaBoost Classifier:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Optionally, print the detailed classification report\n",
    "best_ada = grid_search.best_estimator_\n",
    "test_predictions = best_ada.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "test_predictions_str = test_predictions.astype(int).astype(str)\n",
    "\n",
    "optim_ada_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions_str)], axis=1)\n",
    "optim_ada_submitfile.rename(columns={optim_ada_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "\n",
    "\n",
    "optim_ada_submitfile.to_csv('result_optim_ada.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0d654",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e82c2825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3456 candidates, totalling 10368 fits\n",
      "Best parameters found:  {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score:  0.8496071829405163\n",
      "best Estimator:  RandomForestClassifier(criterion='entropy', max_depth=13, min_samples_leaf=2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Define the parameter grid, including the 'criterion' parameter\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameter grid, including the 'criterion' parameter\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Criterion for split quality\n",
    "    'n_estimators': [10,25,50,100, 150, 200, 250, 300],   # Number of trees in the forest\n",
    "    'max_depth': [None, 5,6,7,8,9,10, 13,15, 20,25, 30],   # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],     # Minimum number of samples required at a leaf node\n",
    "    'bootstrap': [True, False]         # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV with the classifier, parameter grid, and number of folds for cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Optionally, print the detailed classification report\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"best Estimator: \", best_rf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a82a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_rf.predict(X_test)\n",
    "\n",
    "test_predictions_str = test_predictions.astype(int).astype(str)\n",
    "\n",
    "optim_rf_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions_str)], axis=1)\n",
    "optim_rf_submitfile.rename(columns={optim_rf_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "\n",
    "\n",
    "optim_rf_submitfile.to_csv('result_optimized_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaa40f",
   "metadata": {},
   "source": [
    "##  Testing Best Random Forest on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "126f14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': 9, 'n_estimators': 250, 'random_state': 888}\n",
      "Best score:  0.8383968363567886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameter grid, including the 'criterion' parameter\n",
    "params = {\n",
    "    'n_estimators': [250],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [9],\n",
    "    'random_state': [888],\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV with the classifier, parameter grid, and number of folds for cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=4, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Optionally, print the detailed classification report\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "973dd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_rf.predict(X_test)\n",
    "\n",
    "test_predictions_str = test_predictions.astype(int).astype(str)\n",
    "\n",
    "generalized_rf_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions_str)], axis=1)\n",
    "generalized_rf_submitfile.rename(columns={generalized_rf_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "\n",
    "\n",
    "generalized_rf_submitfile.to_csv('result_bestexp_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535be109",
   "metadata": {},
   "source": [
    "## Hyperparamater Tuning Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c794a2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best score: 0.8417362375243238\n",
      "Best parameters found:  {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best score:  0.8417362375243238\n",
      "Best estim:  SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "# Initialize SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Define hyperparameter options\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model\n",
    "# Print the best parameters and the corresponding score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "print(\"Best estim: \", grid_search.best_estimator_)\n",
    "\n",
    "best_svm = grid_search.best_estimator_\n",
    "test_predictions = best_svm.predict(X_test)\n",
    "\n",
    "\n",
    "##test_predictions_str = test_predictions.astype(int).astype(str)\n",
    "##best_svm_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions_str)], axis=1)\n",
    "##best_svm_submitfile.rename(columns={best_svm_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "##best_svm_submitfile.to_csv('result_optim_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ce26d",
   "metadata": {},
   "source": [
    "## Voting Classifier with Random Forest and XGBoost and ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5a1e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=888)\n",
    "##'gamma': 1.0, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'reg_lambda': 1.0\n",
    "gb_clf = GradientBoostingClassifier(learning_rate = .05, max_depth = 5,  n_estimators=100, random_state=42)\n",
    "ab_clf = AdaBoostClassifier(n_estimators=10, learning_rate = 1, random_state=42)\n",
    "\n",
    "# Train the individual classifiers\n",
    "rf_clf.fit(X_train, y_train)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf_clf), \n",
    "                ('gb', gb_clf),\n",
    "                ('ab', ab_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the VotingClassifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "ab_pred = ab_clf.predict(X_test)\n",
    "##y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "\n",
    "test_predictions = voting_clf.predict(X_test)\n",
    "\n",
    "##test_predictions_str = test_predictions.astype(int).astype(str)\n",
    "##generalized_rf_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions_str)], axis=1)\n",
    "##generalized_rf_submitfile.rename(columns={generalized_rf_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "##generalized_rf_submitfile.to_csv('result_bigvoting_soft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7bf9b",
   "metadata": {},
   "source": [
    "## Voting Classifier with SVM and Random Forest\n",
    "\n",
    "#### This is our final model that achieved 79.665%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e240c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# RandomForestClassifier instantiation\n",
    "rf_model = RandomForestClassifier( random_state=888,\n",
    "    n_estimators=250, criterion='gini', max_depth=9, \n",
    "    min_samples_split=10, min_samples_leaf=1, bootstrap=True\n",
    ")\n",
    "\n",
    "\n",
    "# SVC instantiation\n",
    "svm_model = SVC(probability=True, random_state=42, C = 1, gamma = 'scale', kernel = 'linear')  # Enable probability estimation\n",
    "\n",
    "##'C': 1, 'gamma': 'scale', 'kernel': 'linear'\n",
    "\n",
    "\n",
    "# Create voting classifier with added SVM\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "\n",
    "        ('svm', svm_model)  # Add SVM model here\n",
    "    ],\n",
    "    voting='hard'  # Use 'soft' for probability-based voting\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = voting_clf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "test_predictions = voting_clf.predict(X_test)\n",
    "\n",
    "test_predictions_str = test_predictions.astype(int).astype(str)\n",
    "\n",
    "generalized_rf_submitfile = pd.concat([sample_submit_file['PassengerId'], pd.Series(test_predictions_str)], axis=1)\n",
    "generalized_rf_submitfile.rename(columns={generalized_rf_submitfile.columns[1]: 'Survived'}, inplace=True)\n",
    "\n",
    "\n",
    "generalized_rf_submitfile.to_csv('FinalModel.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dbbe897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between RandomForest and SVM predictions: 0.8390136613608257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming X_train, y_train, X_test are already defined\n",
    "\n",
    "# RandomForestClassifier instantiation\n",
    "rf_model = RandomForestClassifier(random_state=888, n_estimators=250, criterion='gini', max_depth=9, \n",
    "                                  min_samples_split=10, min_samples_leaf=1, bootstrap=True)\n",
    "\n",
    "# SVC instantiation\n",
    "svm_model = SVC(probability=True, random_state=42, C=1, gamma='scale', kernel='linear')\n",
    "\n",
    "# Fit both models separately\n",
    "rf_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate the correlation between the two sets of predictions\n",
    "correlation = np.corrcoef(rf_predictions, svm_predictions)[0, 1]\n",
    "\n",
    "print(f\"Correlation between RandomForest and SVM predictions: {correlation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basecopy]",
   "language": "python",
   "name": "conda-env-basecopy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
